{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
    "\n",
    "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
    "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/kapru/Desktop/infosearch-master/quora_question_pairs_rus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
       "      <td>что произойдет, если правительство Индии украд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
       "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
       "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
       "      <td>какая рыба выживет в соленой воде</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
       "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          question1  \\\n",
       "0           0        Какова история кохинор кох-и-ноор-бриллиант   \n",
       "1           1  как я могу увеличить скорость моего интернет-с...   \n",
       "2           2  почему я мысленно очень одинок, как я могу это...   \n",
       "3           3  которые растворяют в воде быстро сахарную соль...   \n",
       "4           4  астрология: я - луна-колпачок из козерога и кр...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  что произойдет, если правительство Индии украд...             0  \n",
       "1  как повысить скорость интернета путем взлома ч...             0  \n",
       "2  найти остаток, когда математика 23 ^ 24 матема...             0  \n",
       "3                  какая рыба выживет в соленой воде             0  \n",
       "4  Я тройная луна-козерог и восхождение в козерог...             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\kapru\\appdata\\roaming\\python\\python37\\site-packages (0.8)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in c:\\users\\kapru\\appdata\\roaming\\python\\python37\\site-packages (from pymorphy2) (2.4.393442.3710985)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\kapru\\appdata\\roaming\\python\\python37\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7 in c:\\users\\kapru\\appdata\\roaming\\python\\python37\\site-packages (from pymorphy2) (0.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Способ 1:** подсчет метрики по формуле для каждой пары слово-документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for row in data['question1'][0:10]:\n",
    "    inputs.append(str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for row in data['question2']:\n",
    "    texts.append(str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kapru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stopwords = set(nltk.corpus.stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize documents\n",
    "BEGIN = 10000\n",
    "N = 10000\n",
    "\n",
    "allWordsAllTexts = []\n",
    "for text in texts[BEGIN:BEGIN+N]:\n",
    "    allWordsInOneText = []\n",
    "    text = re.sub('[^а-яё ]', '', text.lower())\n",
    "    for word in text.split():\n",
    "        if word not in stopwords:\n",
    "            p = morph.parse(word)[0]\n",
    "            if p not in allWordsInOneText:\n",
    "                allWordsInOneText.append(p.normal_form)\n",
    "    allWordsAllTexts.append(allWordsInOneText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['получить', 'доступ', 'анонимный', 'вопрос']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWordsAllTexts[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayString = []\n",
    "for text in allWordsAllTexts:\n",
    "    s = ' '.join(text)\n",
    "    arrayString.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'получить доступ анонимный вопрос'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayString[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(arrayString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "for i in arrayString:\n",
    "    lens.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7591"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgdl = sum([len(doc) for doc in allWordsAllTexts])/len(allWordsAllTexts)\n",
    "avgdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = Matrix/np.array(lens).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "words = vectorizer.get_feature_names()\n",
    "num_doc_qi = np.count_nonzero(Matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, ..., 2, 7, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_doc_qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word):\n",
    "    word_id = words.index(word)\n",
    "    num = num_doc_qi[word_id]\n",
    "    score = log((N - num+0.5)/(num+0.5))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.33798804376911"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('звёздный')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_idfs = []\n",
    "for word in words:\n",
    "    score = idf(word)\n",
    "    all_idfs.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    allWordsInOneInput = []\n",
    "    text = re.sub('[^а-яё ]', '', text.lower())\n",
    "    for word in text.split():\n",
    "        p = morph.parse(word)[0]\n",
    "        allWordsInOneInput.append(p.normal_form)\n",
    "    return allWordsInOneInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['звёздный', 'небо']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('звёздное небо')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_for_words(query, b):\n",
    "    k = 2\n",
    "    q_tokenized = tokenize(query)\n",
    "    results = []\n",
    "    for i in range(N):\n",
    "        bm25 = 0\n",
    "        for j in range(len(q_tokenized)):\n",
    "            word = q_tokenized[j]\n",
    "            if word in words:\n",
    "                word_id = words.index(word)\n",
    "                l = lens[i]\n",
    "                tf_val = tf_matrix[(i,word_id)]\n",
    "                if tf_val != 0:\n",
    "                    tf_new = (tf_val*(k+1.0))/tf_val+k*(1.0-b+b*(l/avgdl))\n",
    "                    bm25 += all_idfs[word_id]*tf_new\n",
    "        results.append(bm25)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = bm25_for_words('джедай', 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_id = bm.index(max(bm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее совпадение - \"почему голливудский учет, где налог избегается, лживая о прибыли - например, возвращение джедаев, по-видимому, никогда не получало прибыли, которую можно было продолжить\"\n"
     ]
    }
   ],
   "source": [
    "print('Лучшее совпадение - ' + '\"' + texts[BEGIN+bm_id] + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 106.97230410575867 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for sent in inputs:\n",
    "    bm = bm25_for_words(sent, 0.75)\n",
    "    bm_id = bm.index(max(bm))\n",
    "    final = texts[BEGIN+bm_id]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Способ:** 2 без умножения векторов на матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "for idx, text in enumerate(allWordsAllTexts):\n",
    "    documents[idx] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['йодский', 'звёздный', 'война', 'стать', 'джедай']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[9621]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "    \n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for docid, terms in documents.items():\n",
    "    for term in terms:\n",
    "        inverted_index[term].add(docid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{768, 2402, 2788, 4641, 6861, 9621}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index['звёздный']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a TF-IDF representation using BM25 \n",
    "\n",
    "NO_DOCS = len(documents) #Number of documents\n",
    "\n",
    "AVG_LEN_DOC = sum([len(doc) for doc in documents.values()])/len(documents) #Average length of documents\n",
    "\n",
    "#The function below takes the documentid, and the term, to calculate scores for the tf and idf\n",
    "#components, and multiplies them together.\n",
    "def tf_idf_score(k1,b,term,docid):  \n",
    "    \n",
    "    ft = len(inverted_index[term]) \n",
    "    term = stemmer.stem(term.lower())\n",
    "    fdt =  documents[docid].count(term)\n",
    "    \n",
    "    idf_comp = math.log((NO_DOCS - ft + 0.5)/(ft+0.5))\n",
    "    \n",
    "    tf_comp = ((k1 + 1)*fdt)/(k1*((1-b) + b*(len(documents[docid])/AVG_LEN_DOC))+fdt)\n",
    "    \n",
    "    return idf_comp * tf_comp\n",
    "\n",
    "#Function to create tf_idf matrix without the query component\n",
    "def create_tf_idf(k1,b):\n",
    "    tf_idf = defaultdict(dict)\n",
    "    for term in set(inverted_index.keys()):\n",
    "        for docid in inverted_index[term]:\n",
    "            tf_idf[term][docid] = tf_idf_score(k1,b,term,docid)\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_DOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7591"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_LEN_DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = create_tf_idf(2.0,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to retrieve query component\n",
    "def get_qtf_comp(k3,term,fqt):\n",
    "    return ((k3+1)*fqt[term])/(k3 + fqt[term])\n",
    "\n",
    "\n",
    "#Function to retrieve documents || Returns a set of documents and their relevance scores. \n",
    "def retr_docs(query,result_count):\n",
    "    q_terms = [stemmer.stem(term.lower()) for term in str(query).split() if term not in stopwords] #Removing stopwords from queries\n",
    "    fqt = {}\n",
    "    for term in q_terms:\n",
    "        fqt[term] = fqt.get(term,0) + 1\n",
    "    \n",
    "    scores = {}\n",
    "    \n",
    "    for word in fqt.keys():\n",
    "        #print word + ': '+ str(inverted_index[word])\n",
    "        for document in inverted_index[word]:\n",
    "            scores[document] = scores.get(document,0) + (tf_idf[word][document]*get_qtf_comp(0,word,fqt)) #k3 chosen as 0 (default)\n",
    "    \n",
    "    return sorted(scores.items(),key = lambda x : x[1] , reverse=True)[:result_count] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(719, 9.115033780888819),\n",
       " (71, 8.074397895821996),\n",
       " (3669, 8.074397895821996),\n",
       " (7163, 8.074397895821996),\n",
       " (7317, 7.247026734974991)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retr_docs(\"путешествие\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['почему', 'путешествие', 'время', 'парадокс']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[7317]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00797891616821289 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for row in inputs:\n",
    "    retr_docs(row,1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** второй способ быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите 10 первых результатов и их близость по метрике BM25 по запросу **рождественские каникулы** на нашем корпусе  Quora question pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7709, 8.879069318533192), (4036, 2.598833886167791)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retr_docs(\"рождественские каникулы\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мочь', 'провести', 'летний', 'каникулы', 'осмысленно']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[7709]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['делать',\n",
       " 'бакалавр',\n",
       " 'область',\n",
       " 'компьютерный',\n",
       " 'наука',\n",
       " 'сделать',\n",
       " 'мой',\n",
       " 'метр',\n",
       " 'семестр',\n",
       " 'несколько',\n",
       " 'день',\n",
       " 'месяц',\n",
       " 'летний',\n",
       " 'каникулы',\n",
       " 'вперёд',\n",
       " 'хороший',\n",
       " 'способ',\n",
       " 'мочь',\n",
       " 'использовать',\n",
       " 'месяц',\n",
       " 'мочь',\n",
       " 'приземлиться',\n",
       " 'хороший',\n",
       " 'стажировка',\n",
       " 'будущее',\n",
       " 'вершина',\n",
       " 'компания',\n",
       " 'надпись',\n",
       " 'тип',\n",
       " 'том',\n",
       " 'далее']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[4036]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "\n",
    "Посчитайте точность поиска при \n",
    "1. BM25, b=0.75 \n",
    "2. BM15, b=0 \n",
    "3. BM11, b=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = (relevant documents & retrieved documents)/retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = bm25_for_words('кофе', 0.75)\n",
    "for i, freq in enumerate(bm25):\n",
    "    bm25[i] = (BEGIN+i, freq)\n",
    "bm25 = list(filter(lambda x: x[1] > 0, bm25))\n",
    "bm25.sort(key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.34018965405718 пить кофе на голодный желудок оказывает слабительное воздействие на меня, это то же самое для других людей\n",
      "165.72690149939353 сколько ключевых слов есть на языке программирования сценариев кофе в последней версии\n",
      "163.85296621260593 глава моей компании с радостью согласился сесть и взять со мной кофе, что я должен спросить у него\n",
      "120.75245461649102 какие наиболее частые неисправности кофе и как их обнаружить\n",
      "85.14768416752652 как я могу получить большую чашку кофе в Starbucks\n",
      "77.6519430203761 каковы преимущества никогда не пить кофе\n",
      "60.78652543928766 варится кофе плохо\n"
     ]
    }
   ],
   "source": [
    "for res in bm25:\n",
    "    print(res[1], texts[res[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# из семи документов два по факту относятся к другому контексту (не напрямую связанном с кофе)\n",
    "precision_bm25=2/7\n",
    "precision_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm15 = bm25_for_words('кофе', 0)\n",
    "for i, freq in enumerate(bm15):\n",
    "    bm15[i] = (BEGIN+i, freq)\n",
    "bm15 = list(filter(lambda x: x[1] > 0, bm15))\n",
    "bm15.sort(key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.97393570046166 сколько ключевых слов есть на языке программирования сценариев кофе в последней версии\n",
      "35.97393570046166 каковы преимущества никогда не пить кофе\n",
      "35.97393570046166 как я могу получить большую чашку кофе в Starbucks\n",
      "35.97393570046166 глава моей компании с радостью согласился сесть и взять со мной кофе, что я должен спросить у него\n",
      "35.97393570046166 пить кофе на голодный желудок оказывает слабительное воздействие на меня, это то же самое для других людей\n",
      "35.97393570046166 какие наиболее частые неисправности кофе и как их обнаружить\n",
      "35.97393570046166 варится кофе плохо\n"
     ]
    }
   ],
   "source": [
    "for res in bm15:\n",
    "    print(res[1], texts[res[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm11 = bm25_for_words('кофе', 1)\n",
    "for i, freq in enumerate(bm11):\n",
    "    bm11[i] = (BEGIN+i, freq)\n",
    "bm11 = list(filter(lambda x: x[1] > 0, bm11))\n",
    "bm11.sort(key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236.46227430525573 пить кофе на голодный желудок оказывает слабительное воздействие на меня, это то же самое для других людей\n",
      "208.9778900990375 сколько ключевых слов есть на языке программирования сценариев кофе в последней версии\n",
      "206.47930971665403 глава моей компании с радостью согласился сесть и взять со мной кофе, что я должен спросить у него\n",
      "149.01196092183415 какие наиболее частые неисправности кофе и как их обнаружить\n",
      "101.53893365654814 как я могу получить большую чашку кофе в Starbucks\n",
      "91.54461212701425 каковы преимущества никогда не пить кофе\n",
      "69.05738868556298 варится кофе плохо\n"
     ]
    }
   ],
   "source": [
    "for res in bm11:\n",
    "    print(res[1], texts[res[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
